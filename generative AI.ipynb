{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673bfee1",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c7d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937f861",
   "metadata": {},
   "source": [
    "Custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b713bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of importing, define directly in this notebook\n",
    "\n",
    "def get_required_skills_from_linkedin():\n",
    "    # Dummy function to simulate skill scraping\n",
    "    return [\"Python\", \"LangChain\", \"RAG\", \"Fine-tuning\", \"MCP\", \"LLMs\"]\n",
    "\n",
    "def find_courses_from_coursera():\n",
    "    # Dummy function to simulate course recommendation\n",
    "    return [\"LangChain with LLMs\", \"Advanced Hugging Face Transformers\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0a11e",
   "metadata": {},
   "source": [
    "Initialize the language model and memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c1583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/zv5h04nn7jv_k2q7mxzvpvww0000gn/T/ipykernel_1777/834378571.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationBufferMemory(memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:221\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     emit_warning()\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'model...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b82b0c",
   "metadata": {},
   "source": [
    "Define the tools the agent can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"LinkedInSkillScraper\",\n",
    "        func=get_required_skills_from_linkedin,\n",
    "        description=\"Fetch required skills for a given job title from LinkedIn job posts.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CourseraCourseFinder\",\n",
    "        func=find_courses_from_coursera,\n",
    "        description=\"Find online Coursera courses for a list of skills.\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2156c",
   "metadata": {},
   "source": [
    "Initialize the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a203c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083d2e6",
   "metadata": {},
   "source": [
    "Prompt templates for SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roadmap_template = PromptTemplate(\n",
    "    input_variables=[\"user_background\", \"skills_and_courses\"],\n",
    "    template=\"\"\"\n",
    "You are an expert career coach. Based on the user's background:\n",
    "{user_background}\n",
    "\n",
    "And the following skills and courses:\n",
    "{skills_and_courses}\n",
    "\n",
    "Create a 6-month personalized learning roadmap.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "roadmap_chain = LLMChain(llm=llm, prompt=roadmap_template, output_key=\"roadmap\")\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[roadmap_chain],\n",
    "    input_variables=[\"user_background\", \"skills_and_courses\"],\n",
    "    output_variables=[\"roadmap\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae8186",
   "metadata": {},
   "source": [
    " Run the full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_goal = input(\"Describe your current role and the job you want to get: \")\n",
    "    agent_response = agent.run(user_goal)\n",
    "    print(\"\\nðŸ” Agent reasoning complete.\")\n",
    "\n",
    "    inputs = {\n",
    "        \"user_background\": user_goal,\n",
    "        \"skills_and_courses\": agent_response\n",
    "    }\n",
    "    roadmap_output = sequential_chain(inputs)\n",
    "\n",
    "    print(\"\\nðŸ“‹ Personalized Learning Roadmap:\\n\")\n",
    "    print(roadmap_output['roadmap'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73c641",
   "metadata": {},
   "source": [
    "tools//job_skill_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c41f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_required_skills_from_linkedin(job_title: str) -> str:\n",
    "    # This is a simplified simulation. In production, you would use LinkedIn's official API or a service like SerpAPI.\n",
    "    query = job_title.replace(\" \", \"+\")\n",
    "    url = f\"https://www.linkedin.com/jobs/search/?keywords={query}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        # In production, you'd parse real skills here\n",
    "        return \"Python, Machine Learning, Data Science, TensorFlow, SQL\"\n",
    "    else:\n",
    "        return \"Unable to fetch skills from LinkedIn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761c5b5",
   "metadata": {},
   "source": [
    "tools/course_finder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def find_courses_from_coursera(skills: str) -> str:\n",
    "    skills_list = skills.split(\", \")\n",
    "    results = []\n",
    "    for skill in skills_list:\n",
    "        query = skill.replace(\" \", \"%20\")\n",
    "        url = f\"https://api.coursera.org/api/courses.v1?q=search&query={query}&limit=1\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data.get(\"elements\"):\n",
    "                course = data[\"elements\"][0]\n",
    "                title = course.get(\"name\", \"No Title\")\n",
    "                results.append(f\"{skill}: {title} (Coursera)\")\n",
    "            else:\n",
    "                results.append(f\"{skill}: No course found\")\n",
    "        else:\n",
    "            results.append(f\"{skill}: Error fetching course\")\n",
    "    return \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6e3fc",
   "metadata": {},
   "source": [
    "chains/roadmap_chain.py (no longer needed separately but kept for legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_roadmap(user_background: str, agent_summary: str) -> str:\n",
    "    return f\"\"\"\n",
    "User Background: {user_background}\n",
    "\n",
    "Skills & Learning Resources Identified:\n",
    "{agent_summary}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
